{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import precision_score, accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MVAE Model Definition\n",
    "class MVAE(nn.Module):\n",
    "    def __init__(self, vocab_size, image_embed_size, latent_dim, reg_lambda, fnd_lambda):\n",
    "        super(MVAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.reg_lambda = reg_lambda\n",
    "        self.fnd_lambda = fnd_lambda\n",
    "\n",
    "        # Encoder layers\n",
    "        self.txt_embedding = nn.Embedding(vocab_size, 32)\n",
    "        self.lstm_txt1 = nn.LSTM(32, 32, bidirectional=True, batch_first=True)\n",
    "        self.lstm_txt2 = nn.LSTM(64, 32, bidirectional=True, batch_first=False)\n",
    "        self.fc_txt = nn.Linear(64, 32)\n",
    "        \n",
    "        self.fc_img1 = nn.Linear(image_embed_size, 1024)\n",
    "        self.fc_img2 = nn.Linear(1024, 32)\n",
    "\n",
    "        self.fc_shared = nn.Linear(64, 64)\n",
    "\n",
    "        self.fc_mean = nn.Linear(64, latent_dim)\n",
    "        self.fc_log_var = nn.Linear(64, latent_dim)\n",
    "\n",
    "        # Decoder layers\n",
    "        self.fc_dec_txt = nn.Linear(latent_dim, 32)\n",
    "        self.lstm_dec_txt1 = nn.LSTM(32, 32, batch_first=True)\n",
    "        self.lstm_dec_txt2 = nn.LSTM(32, 32, batch_first=True)\n",
    "        self.fc_dec_output_txt = nn.Linear(32, vocab_size)\n",
    "\n",
    "        self.fc_dec_img1 = nn.Linear(latent_dim, 32)\n",
    "        self.fc_dec_img2 = nn.Linear(32, 1024)\n",
    "        self.fc_dec_output_img = nn.Linear(1024, 4096)\n",
    "\n",
    "        # FND layers\n",
    "        self.fnd_fc1 = nn.Linear(latent_dim, 64)\n",
    "        self.fnd_fc2 = nn.Linear(64, 32)\n",
    "        self.fnd_output = nn.Linear(32, 1)\n",
    "\n",
    "    def encode(self, x_txt, x_img):\n",
    "        embedded_txt = self.txt_embedding(x_txt)\n",
    "        lstm_out1, _ = self.lstm_txt1(embedded_txt)\n",
    "        lstm_out2, _ = self.lstm_txt2(lstm_out1)\n",
    "        txt_features = self.fc_txt(lstm_out2[:,-1,:])\n",
    "        #print(\"Text features shape:\", txt_features.shape)  # Should be [128, 32]\n",
    "\n",
    "        img_features = self.fc_img2(torch.tanh(self.fc_img1(x_img)))\n",
    "        #print(img_features.shape)\n",
    "\n",
    "        h = torch.cat((txt_features, img_features), dim=-1)\n",
    "        h = torch.tanh(self.fc_shared(h))\n",
    "\n",
    "        z_mean = self.fc_mean(h)\n",
    "        z_log_var = self.fc_log_var(h)\n",
    "\n",
    "        return z_mean, z_log_var\n",
    "\n",
    "    def reparameterize(self, z_mean, z_log_var):\n",
    "        std = torch.exp(0.5 * z_log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return z_mean + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        dec_txt = self.fc_dec_txt(z)\n",
    "        dec_txt = dec_txt.unsqueeze(1).repeat(1, 20, 1)  # Repeat for sequence length\n",
    "        lstm_dec_out1, _ = self.lstm_dec_txt1(dec_txt)\n",
    "        lstm_dec_out2, _ = self.lstm_dec_txt2(lstm_dec_out1)\n",
    "        decoded_txt = self.fc_dec_output_txt(lstm_dec_out2)\n",
    "\n",
    "        dec_img = torch.tanh(self.fc_dec_img1(z))\n",
    "        decoded_img = torch.sigmoid(self.fc_dec_output_img(self.fc_dec_img2(dec_img)))\n",
    "\n",
    "        return decoded_txt, decoded_img\n",
    "\n",
    "    def fnd(self, z):\n",
    "        h = torch.tanh(self.fnd_fc1(z))\n",
    "        h = torch.tanh(self.fnd_fc2(h))\n",
    "        return torch.sigmoid(self.fnd_output(h))\n",
    "\n",
    "    def forward(self, x_txt, x_img):\n",
    "        z_mean, z_log_var = self.encode(x_txt, x_img)\n",
    "        z = self.reparameterize(z_mean, z_log_var)\n",
    "        decoded_txt, decoded_img = self.decode(z)\n",
    "        fnd_output = self.fnd(z)\n",
    "        return decoded_txt, decoded_img, fnd_output, z_mean, z_log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn.functional as F\n",
    "# #import pandas as pd\n",
    "# # Training Function\n",
    "# def train(sequence_length, image_embed_size, latent_dim, reg_lambda, fnd_lambda, path):\n",
    "#     device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#     print(f\"Using device: {device}\")\n",
    "#     text = np.load('data/train_text.npy')\n",
    "#     im = np.load('data/train_image_embed.npy')\n",
    "#     label = np.load('data/train_label.npy')[:, 1]\n",
    "\n",
    "#     test_text = np.load('data/test_text.npy')\n",
    "#     test_im = np.load('data/test_image_embed.npy')\n",
    "#     test_label = np.load('data/test_label.npy')[:, 1]\n",
    "\n",
    "#     embed_matrix = np.load('data/embedding_matrix.npy')\n",
    "#     vocab_size = embed_matrix.shape[0]\n",
    "\n",
    "#     # Convert to PyTorch tensors\n",
    "#     train_data = TensorDataset(torch.LongTensor(text), torch.FloatTensor(im), torch.FloatTensor(label))\n",
    "#     train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "\n",
    "#     model = MVAE(vocab_size, image_embed_size, latent_dim, reg_lambda, fnd_lambda)\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "#     model.train()\n",
    "#     loss_data = []\n",
    "#     for epoch in range(300):\n",
    "#         for batch in train_loader:\n",
    "#             x_txt, x_img, y_fnd = batch\n",
    "#             #print(\"Shape of x_txt:\", x_txt.shape)\n",
    "#             #print(\"Shape of x_img:\", x_img.shape)\n",
    "\n",
    "#             optimizer.zero_grad()\n",
    "#             decoded_txt, decoded_img, fnd_output, z_mean, z_log_var = model(x_txt, x_img)\n",
    "            \n",
    "#             # Normalize x_img embeddings to unit vectors\n",
    "#             x_img_normalized = F.normalize(x_img, p=2, dim=1)  # L2 normalization\n",
    "            \n",
    "            \n",
    "#             # #print('decode_img: ', decoded_img.shape)\n",
    "#             # #print('x_img: ', x_img.shape)\n",
    "#             # # Check the maximum and minimum values\n",
    "#             # min_value = x_img.min()\n",
    "#             # max_value = x_img.max()\n",
    "\n",
    "#             # print(f\"Min value in x_img: {min_value.item()}\")\n",
    "#             # print(f\"Max value in x_img: {max_value.item()}\")\n",
    "#             # min_value = decoded_img.min()\n",
    "#             # max_value = decoded_img.max()\n",
    "\n",
    "#             # print(f\"Min value in x_img: {min_value.item()}\")\n",
    "#             # print(f\"Max value in x_img: {max_value.item()}\")\n",
    "\n",
    "#             # Loss calculations\n",
    "#             recon_loss = nn.CrossEntropyLoss()(decoded_txt.view(-1, vocab_size), x_txt.view(-1))\n",
    "#             recon_img_loss = nn.BCELoss()(decoded_img, x_img_normalized)\n",
    "#             fnd_loss = nn.BCELoss()(fnd_output.view(-1), y_fnd)\n",
    "\n",
    "#             # KL divergence\n",
    "#             kl_loss = -0.5 * torch.mean(1 + z_log_var - z_mean.pow(2) - z_log_var.exp())\n",
    "#             loss = recon_loss + recon_img_loss + fnd_loss + kl_loss\n",
    "#             loss_data.append(loss)\n",
    "\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#         print(f'Epoch {epoch + 1}, Loss: {loss.item()}')\n",
    "\n",
    "#     # Save model\n",
    "#     if not os.path.exists(path):\n",
    "#         os.makedirs(path)\n",
    "#     torch.save(model.state_dict(), os.path.join(path, 'mvae.pth'))\n",
    "#     # Convert the list to a DataFrame\n",
    "#     # df = pd.DataFrame(loss_data, columns=['Loss'])\n",
    "\n",
    "#     # # Save the DataFrame to a CSV file\n",
    "#     # df.to_csv('loss_data.csv', index=False)  # index=False to avoid saving the index column\n",
    "#     # Open a text file in write mode\n",
    "#     with open('loss_data.txt', 'w') as f:\n",
    "#         for loss in loss_data:\n",
    "#             f.write(f\"{loss}\\n\")  # Write each loss value on a new line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# Training Function\n",
    "def train(sequence_length, image_embed_size, latent_dim, reg_lambda, fnd_lambda, path):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Load data\n",
    "    text = np.load('data/train_text.npy')\n",
    "    im = np.load('data/train_image_embed.npy')\n",
    "    label = np.load('data/train_label.npy')[:, 1]\n",
    "\n",
    "    test_text = np.load('data/test_text.npy')\n",
    "    test_im = np.load('data/test_image_embed.npy')\n",
    "    test_label = np.load('data/test_label.npy')[:, 1]\n",
    "\n",
    "    embed_matrix = np.load('data/embedding_matrix.npy')\n",
    "    vocab_size = embed_matrix.shape[0]\n",
    "\n",
    "    # Convert to PyTorch tensors and move to the selected device (CUDA or CPU)\n",
    "    train_data = TensorDataset(\n",
    "        torch.LongTensor(text).to(device), \n",
    "        torch.FloatTensor(im).to(device), \n",
    "        torch.FloatTensor(label).to(device)\n",
    "    )\n",
    "    train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "\n",
    "    # Initialize model and move it to the device (CUDA or CPU)\n",
    "    model = MVAE(vocab_size, image_embed_size, latent_dim, reg_lambda, fnd_lambda).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "    model.train()\n",
    "    loss_data = []\n",
    "    \n",
    "    for epoch in range(150):\n",
    "        for batch in train_loader:\n",
    "            x_txt, x_img, y_fnd = batch  # Already moved to the device\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            decoded_txt, decoded_img, fnd_output, z_mean, z_log_var = model(x_txt, x_img)\n",
    "\n",
    "            # Normalize x_img embeddings to unit vectors\n",
    "            x_img_normalized = F.normalize(x_img, p=2, dim=1)  # L2 normalization\n",
    "\n",
    "            # Loss calculations\n",
    "            recon_loss = nn.CrossEntropyLoss()(decoded_txt.view(-1, vocab_size), x_txt.view(-1))\n",
    "            recon_img_loss = nn.BCELoss()(decoded_img, x_img_normalized)\n",
    "            fnd_loss = nn.BCELoss()(fnd_output.view(-1), y_fnd)\n",
    "            # print(y_fnd.shape)\n",
    "            # print(fnd_output.shape)\n",
    "\n",
    "            # KL divergence\n",
    "            kl_loss = -0.5 * torch.mean(1 + z_log_var - z_mean.pow(2) - z_log_var.exp())\n",
    "\n",
    "            # Total loss\n",
    "            loss = recon_loss + recon_img_loss + fnd_loss + kl_loss\n",
    "            \n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f'Epoch {epoch + 1}, Loss: {loss.item()}')\n",
    "        loss_data.append(loss.item())  # Use .item() to extract the scalar value for logging\n",
    "\n",
    "    # Save model\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    #torch.save(model.state_dict(), os.path.join(path, 'mvae.pth'))\n",
    "\n",
    "    # Save loss data to a text file\n",
    "    with open('loss_data.txt', 'w') as f:\n",
    "        for loss in loss_data:\n",
    "            f.write(f\"{loss}\\n\")  # Write each loss value on a new line\n",
    "    return loss_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import torch.nn.functional as F\n",
    "# from torch.utils.data import DataLoader, TensorDataset\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# import numpy as np\n",
    "# import os\n",
    "\n",
    "# # Training Function\n",
    "# def train(sequence_length, image_embed_size, latent_dim, reg_lambda, fnd_lambda, path):\n",
    "#     device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#     print(f\"Using device: {device}\")\n",
    "\n",
    "#     # Load data\n",
    "#     text = np.load('data/train_text.npy')\n",
    "#     im = np.load('data/train_image_embed.npy')\n",
    "#     label = np.load('data/train_label.npy')[:, 1]\n",
    "\n",
    "#     # Split the data into training and validation sets\n",
    "#     text_train, text_val, im_train, im_val, label_train, label_val = train_test_split(\n",
    "#         text, im, label, test_size=0.2, random_state=42  # Adjust test_size as needed\n",
    "#     )\n",
    "\n",
    "#     # Convert to PyTorch tensors and move to the selected device (CUDA or CPU)\n",
    "#     train_data = TensorDataset(\n",
    "#         torch.LongTensor(text_train).to(device), \n",
    "#         torch.FloatTensor(im_train).to(device), \n",
    "#         torch.FloatTensor(label_train).to(device)\n",
    "#     )\n",
    "#     train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "\n",
    "#     val_data = TensorDataset(\n",
    "#         torch.LongTensor(text_val).to(device),\n",
    "#         torch.FloatTensor(im_val).to(device),\n",
    "#         torch.FloatTensor(label_val).to(device)\n",
    "#     )\n",
    "#     val_loader = DataLoader(val_data, batch_size=128, shuffle=False)\n",
    "\n",
    "#     # Initialize model and optimizer\n",
    "#     model = MVAE(sequence_length, image_embed_size, latent_dim, reg_lambda, fnd_lambda).to(device)\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "#     model.train()\n",
    "#     loss_data = []\n",
    "#     val_loss_data = []  # To store validation losses\n",
    "\n",
    "#     for epoch in range(150):\n",
    "#         # Training phase\n",
    "#         for batch in train_loader:\n",
    "#             x_txt, x_img, y_fnd = batch\n",
    "            \n",
    "#             optimizer.zero_grad()\n",
    "\n",
    "#             # Forward pass\n",
    "#             decoded_txt, decoded_img, fnd_output, z_mean, z_log_var = model(x_txt, x_img)\n",
    "\n",
    "#             # Normalize x_img embeddings to unit vectors\n",
    "#             x_img_normalized = F.normalize(x_img, p=2, dim=1)\n",
    "\n",
    "#             # Loss calculations\n",
    "#             recon_loss = nn.CrossEntropyLoss()(decoded_txt.view(-1, sequence_length), x_txt.view(-1))\n",
    "#             recon_img_loss = nn.BCELoss()(decoded_img, x_img_normalized)\n",
    "#             fnd_loss = nn.BCELoss()(fnd_output.view(-1), y_fnd)\n",
    "\n",
    "#             # KL divergence\n",
    "#             kl_loss = -0.5 * torch.mean(1 + z_log_var - z_mean.pow(2) - z_log_var.exp())\n",
    "\n",
    "#             # Total loss\n",
    "#             loss = recon_loss + recon_img_loss + fnd_loss + kl_loss\n",
    "            \n",
    "#             # Backward pass and optimization\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#         print(f'Epoch {epoch + 1}, Training Loss: {loss.item()}')\n",
    "#         loss_data.append(loss.item())\n",
    "\n",
    "#         # Validation phase\n",
    "#         model.eval()\n",
    "#         val_loss = 0.0  # Initialize validation loss\n",
    "\n",
    "#         with torch.no_grad():  # Disable gradient calculation for validation\n",
    "#             for val_batch in val_loader:\n",
    "#                 x_txt, x_img, y_fnd = val_batch\n",
    "                \n",
    "#                 decoded_txt, decoded_img, fnd_output, z_mean, z_log_var = model(x_txt, x_img)\n",
    "                \n",
    "#                 # Loss calculations for validation\n",
    "#                 recon_loss = nn.CrossEntropyLoss()(decoded_txt.view(-1, sequence_length), x_txt.view(-1))\n",
    "#                 recon_img_loss = nn.BCELoss()(decoded_img, F.normalize(x_img, p=2, dim=1))\n",
    "#                 fnd_loss = nn.BCELoss()(fnd_output.view(-1), y_fnd)\n",
    "\n",
    "#                 kl_loss = -0.5 * torch.mean(1 + z_log_var - z_mean.pow(2) - z_log_var.exp())\n",
    "\n",
    "#                 # Total validation loss\n",
    "#                 val_loss += (recon_loss + recon_img_loss + fnd_loss + kl_loss).item()\n",
    "\n",
    "#         val_loss /= len(val_loader)  # Average validation loss\n",
    "#         print(f'Epoch {epoch + 1}, Validation Loss: {val_loss}')\n",
    "#         val_loss_data.append(val_loss)\n",
    "\n",
    "#     # Save model\n",
    "#     if not os.path.exists(path):\n",
    "#         os.makedirs(path)\n",
    "#     # torch.save(model.state_dict(), os.path.join(path, 'mvae.pth'))\n",
    "\n",
    "#     # Save loss data to a text file\n",
    "#     with open('loss_data.txt', 'w') as f:\n",
    "#         for loss in loss_data:\n",
    "#             f.write(f\"{loss}\\n\")  # Write each training loss value on a new line\n",
    "\n",
    "#     with open('val_loss_data.txt', 'w') as f:\n",
    "#         for val_loss in val_loss_data:\n",
    "#             f.write(f\"{val_loss}\\n\")  # Write each validation loss value on a new line\n",
    "            \n",
    "#     return loss_data, val_loss_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Function\n",
    "def test(sequence_length, image_embed_size, latent_dim, reg_lambda, fnd_lambda, path):\n",
    "    test_text = np.load('data/test_text.npy')\n",
    "    test_im = np.load('data/test_image_embed.npy')\n",
    "    test_label = np.load('data/test_label.npy')[:, 1]\n",
    "\n",
    "    embed_matrix = np.load('data/embedding_matrix.npy')\n",
    "    vocab_size = embed_matrix.shape[0]\n",
    "\n",
    "    model = MVAE(vocab_size, image_embed_size, latent_dim, reg_lambda, fnd_lambda)\n",
    "    model.load_state_dict(torch.load(os.path.join(path, 'mvae.pth')))\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        x_txt = torch.LongTensor(test_text)\n",
    "        x_img = torch.FloatTensor(test_im)\n",
    "        # Normalize x_img embeddings to unit vectors\n",
    "        x_img_normalized = F.normalize(x_img, p=2, dim=1)  # L2 normalization\n",
    "        \n",
    "        # Model prediction\n",
    "        pred = model(x_txt, x_img_normalized)[-1]  # Last output is the prediction\n",
    "        \n",
    "        # Use only the first class's predictions (e.g., index 0)\n",
    "        first_class_pred = pred[:, 0]  # Get the predictions for the first class\n",
    "        # Convert to binary (e.g., using a threshold of 0.5)\n",
    "        binary_pred = (first_class_pred > 0.5).float()\n",
    "\n",
    "        # Convert PyTorch tensors to NumPy arrays for evaluation\n",
    "        pred_np = binary_pred.cpu().numpy()  # Move tensor to CPU and convert to NumPy array\n",
    "        test_label_np = test_label  # test_label is already a NumPy array\n",
    "        \n",
    "        # Print the shapes of the predictions and true labels for debugging\n",
    "        print(f\"Shape of pred_np: {pred_np.shape}\")\n",
    "        print(f\"Shape of test_label_np: {test_label_np.shape}\")\n",
    "\n",
    "        # Flatten the arrays to ensure they're 1D binary arrays\n",
    "        pred_np = pred_np.flatten()\n",
    "        test_label_np = test_label_np.flatten()\n",
    "\n",
    "        accuracy = accuracy_score(test_label, pred_np)\n",
    "        #precision = precision_score(test_label, pred_np)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(test_label, pred_np, average='binary')\n",
    "\n",
    "        print(f'Accuracy: {accuracy}')\n",
    "        print(f'Precision: {precision}')\n",
    "        print(f'Recall: {recall}')\n",
    "        print(f'F1 Score: {f1}')\n",
    "        return test_label_np, pred_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m    loss_data\u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4096\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodels/mvae\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m    \u001b[38;5;66;03m# test(20, 4096, 64, 0.05, 0.3, 'models/mvae')\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 23\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(sequence_length, image_embed_size, latent_dim, reg_lambda, fnd_lambda, path)\u001b[0m\n\u001b[0;32m     19\u001b[0m vocab_size \u001b[38;5;241m=\u001b[39m embed_matrix\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Convert to PyTorch tensors and move to the selected device (CUDA or CPU)\u001b[39;00m\n\u001b[0;32m     22\u001b[0m train_data \u001b[38;5;241m=\u001b[39m TensorDataset(\n\u001b[1;32m---> 23\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLongTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m, \n\u001b[0;32m     24\u001b[0m     torch\u001b[38;5;241m.\u001b[39mFloatTensor(im)\u001b[38;5;241m.\u001b[39mto(device), \n\u001b[0;32m     25\u001b[0m     torch\u001b[38;5;241m.\u001b[39mFloatTensor(label)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     26\u001b[0m )\n\u001b[0;32m     27\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_data, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Initialize model and move it to the device (CUDA or CPU)\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "   loss_data= train(20, 4096, 64, 0.05, 0.3, 'models/mvae')\n",
    "   # test(20, 4096, 64, 0.05, 0.3, 'models/mvae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Training Function\n",
    "def train(sequence_length, image_embed_size, latent_dim, reg_lambda, fnd_lambda, path):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Load data\n",
    "    text = np.load('data/train_text.npy')\n",
    "    im = np.load('data/train_image_embed.npy')\n",
    "    label = np.load('data/train_label.npy')[:, 1]\n",
    "\n",
    "    # Split the data into training and validation sets\n",
    "    text_train, text_val, im_train, im_val, label_train, label_val = train_test_split(\n",
    "        text, im, label, test_size=0.2, random_state=42  # Adjust test_size as needed\n",
    "    )\n",
    "\n",
    "    # Convert to PyTorch tensors and move to the selected device (CUDA or CPU)\n",
    "    train_data = TensorDataset(\n",
    "        torch.LongTensor(text_train).to(device), \n",
    "        torch.FloatTensor(im_train).to(device), \n",
    "        torch.FloatTensor(label_train).to(device)\n",
    "    )\n",
    "    train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "\n",
    "    val_data = TensorDataset(\n",
    "        torch.LongTensor(text_val).to(device),\n",
    "        torch.FloatTensor(im_val).to(device),\n",
    "        torch.FloatTensor(label_val).to(device)\n",
    "    )\n",
    "    val_loader = DataLoader(val_data, batch_size=128, shuffle=False)\n",
    "\n",
    "    # Initialize model and optimizer\n",
    "    model = MVAE(vocab_size, image_embed_size, latent_dim, reg_lambda, fnd_lambda).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "    model.train()\n",
    "    loss_data = []\n",
    "    val_loss_data = []  # To store validation losses\n",
    "\n",
    "    for epoch in range(150):\n",
    "        # Training phase\n",
    "        for batch in train_loader:\n",
    "            x_txt, x_img, y_fnd = batch\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            decoded_txt, decoded_img, fnd_output, z_mean, z_log_var = model(x_txt, x_img)\n",
    "\n",
    "            # Normalize x_img embeddings to unit vectors\n",
    "            x_img_normalized = F.normalize(x_img, p=2, dim=1)\n",
    "\n",
    "            # Loss calculations\n",
    "            recon_loss = nn.CrossEntropyLoss()(decoded_txt.view(-1, vocab_size), x_txt.view(-1))\n",
    "            recon_img_loss = nn.BCELoss()(decoded_img, x_img_normalized)\n",
    "            fnd_loss = nn.BCELoss()(fnd_output.view(-1), y_fnd)\n",
    "\n",
    "            # KL divergence\n",
    "            kl_loss = -0.5 * torch.mean(1 + z_log_var - z_mean.pow(2) - z_log_var.exp())\n",
    "\n",
    "            # Total loss\n",
    "            loss = recon_loss + recon_img_loss + fnd_loss + kl_loss\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f'Epoch {epoch + 1}, Training Loss: {loss.item()}')\n",
    "        loss_data.append(loss.item())\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0  # Initialize validation loss\n",
    "\n",
    "        with torch.no_grad():  # Disable gradient calculation for validation\n",
    "            for val_batch in val_loader:\n",
    "                x_txt, x_img, y_fnd = val_batch\n",
    "                \n",
    "                decoded_txt, decoded_img, fnd_output, z_mean, z_log_var = model(x_txt, x_img)\n",
    "                \n",
    "                # Loss calculations for validation\n",
    "                recon_loss = nn.CrossEntropyLoss()(decoded_txt.view(-1, vocab_size), x_txt.view(-1))\n",
    "                recon_img_loss = nn.BCELoss()(decoded_img, F.normalize(x_img, p=2, dim=1))\n",
    "                fnd_loss = nn.BCELoss()(fnd_output.view(-1), y_fnd)\n",
    "\n",
    "                kl_loss = -0.5 * torch.mean(1 + z_log_var - z_mean.pow(2) - z_log_var.exp())\n",
    "\n",
    "                # Total validation loss\n",
    "                val_loss += (recon_loss + recon_img_loss + fnd_loss + kl_loss).item()\n",
    "\n",
    "        val_loss /= len(val_loader)  # Average validation loss\n",
    "        print(f'Epoch {epoch + 1}, Validation Loss: {val_loss}')\n",
    "        val_loss_data.append(val_loss)\n",
    "\n",
    "    # Save model\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    # torch.save(model.state_dict(), os.path.join(path, 'mvae.pth'))\n",
    "\n",
    "    # Save loss data to a text file\n",
    "    with open('loss_data.txt', 'w') as f:\n",
    "        for loss in loss_data:\n",
    "            f.write(f\"{loss}\\n\")  # Write each training loss value on a new line\n",
    "\n",
    "    with open('val_loss_data.txt', 'w') as f:\n",
    "        for val_loss in val_loss_data:\n",
    "            f.write(f\"{val_loss}\\n\")  # Write each validation loss value on a new line\n",
    "            \n",
    "    return loss_data, val_loss_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m    loss_data, val_loss_data \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4096\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodels/mvae\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m    \u001b[38;5;66;03m# test(20, 4096, 64, 0.05, 0.3, 'models/mvae')\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[12], line 23\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(sequence_length, image_embed_size, latent_dim, reg_lambda, fnd_lambda, path)\u001b[0m\n\u001b[0;32m     19\u001b[0m vocab_size \u001b[38;5;241m=\u001b[39m embed_matrix\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Convert to PyTorch tensors and move to the selected device (CUDA or CPU)\u001b[39;00m\n\u001b[0;32m     22\u001b[0m train_data \u001b[38;5;241m=\u001b[39m TensorDataset(\n\u001b[1;32m---> 23\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLongTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m, \n\u001b[0;32m     24\u001b[0m     torch\u001b[38;5;241m.\u001b[39mFloatTensor(im)\u001b[38;5;241m.\u001b[39mto(device), \n\u001b[0;32m     25\u001b[0m     torch\u001b[38;5;241m.\u001b[39mFloatTensor(label)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     26\u001b[0m )\n\u001b[0;32m     27\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_data, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Initialize model and move it to the device (CUDA or CPU)\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "   loss_data, val_loss_data = train(20, 4096, 64, 0.05, 0.3, 'models/mvae')\n",
    "   # test(20, 4096, 64, 0.05, 0.3, 'models/mvae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\swaru\\AppData\\Local\\Temp\\ipykernel_49060\\1027288476.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(os.path.join(path, 'mvae.pth')))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test_label_np, pred_np\u001b[38;5;241m=\u001b[39m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4096\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodels/mvae\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 11\u001b[0m, in \u001b[0;36mtest\u001b[1;34m(sequence_length, image_embed_size, latent_dim, reg_lambda, fnd_lambda, path)\u001b[0m\n\u001b[0;32m      8\u001b[0m vocab_size \u001b[38;5;241m=\u001b[39m embed_matrix\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m MVAE(vocab_size, image_embed_size, latent_dim, reg_lambda, fnd_lambda)\n\u001b[1;32m---> 11\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmvae.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     12\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\serialization.py:1097\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1095\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1096\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1097\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[0;32m   1098\u001b[0m             opened_zipfile,\n\u001b[0;32m   1099\u001b[0m             map_location,\n\u001b[0;32m   1100\u001b[0m             pickle_module,\n\u001b[0;32m   1101\u001b[0m             overall_storage\u001b[38;5;241m=\u001b[39moverall_storage,\n\u001b[0;32m   1102\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args,\n\u001b[0;32m   1103\u001b[0m         )\n\u001b[0;32m   1104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[0;32m   1105\u001b[0m     f_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\serialization.py:1525\u001b[0m, in \u001b[0;36m_load\u001b[1;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# Needed for tensors where storage device and rebuild tensor device are\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# not connected (wrapper subclasses and tensors rebuilt using numpy)\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_thread_local_state\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m map_location\n\u001b[1;32m-> 1525\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1526\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_thread_local_state\u001b[38;5;241m.\u001b[39mmap_location\n\u001b[0;32m   1528\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\serialization.py:1492\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[1;34m(saved_id)\u001b[0m\n\u001b[0;32m   1490\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1491\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[1;32m-> 1492\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1494\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\serialization.py:1466\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[1;34m(dtype, numel, key, location)\u001b[0m\n\u001b[0;32m   1461\u001b[0m         storage\u001b[38;5;241m.\u001b[39mbyteswap(dtype)\n\u001b[0;32m   1463\u001b[0m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[0;32m   1465\u001b[0m typed_storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mTypedStorage(\n\u001b[1;32m-> 1466\u001b[0m     wrap_storage\u001b[38;5;241m=\u001b[39m\u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   1467\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1468\u001b[0m     _internal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typed_storage\u001b[38;5;241m.\u001b[39m_data_ptr() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1471\u001b[0m     loaded_storages[key] \u001b[38;5;241m=\u001b[39m typed_storage\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\serialization.py:414\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[1;34m(storage, location)\u001b[0m\n\u001b[0;32m    412\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_restore_location\u001b[39m(storage, location):\n\u001b[0;32m    413\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[1;32m--> 414\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    415\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    416\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\serialization.py:392\u001b[0m, in \u001b[0;36m_deserialize\u001b[1;34m(backend_name, obj, location)\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m location\u001b[38;5;241m.\u001b[39mstartswith(backend_name):\n\u001b[0;32m    391\u001b[0m     device \u001b[38;5;241m=\u001b[39m _validate_device(location, backend_name)\n\u001b[1;32m--> 392\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\storage.py:187\u001b[0m, in \u001b[0;36m_StorageBase.to\u001b[1;34m(self, device, non_blocking)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, device: torch\u001b[38;5;241m.\u001b[39mdevice, non_blocking: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:  \u001b[38;5;66;03m# type: ignore[type-var, misc] # noqa: E704\u001b[39;00m\n\u001b[1;32m--> 187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_to\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\_utils.py:90\u001b[0m, in \u001b[0;36m_to\u001b[1;34m(self, device, non_blocking)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_sparse\n\u001b[0;32m     88\u001b[0m ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse storage is not supported for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     89\u001b[0m untyped_storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mUntypedStorage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize(), device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m---> 90\u001b[0m \u001b[43muntyped_storage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m untyped_storage\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "test_label_np, pred_np=test(20, 4096, 64, 0.05, 0.3, 'models/mvae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 1, 0], dtype=int32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.0)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_np.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31800"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.size(loss_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 2: Plot the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(loss_data, label='Loss', color='blue', linewidth=2)\n",
    "\n",
    "# Step 3: Customize the plot\n",
    "plt.title('Loss Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Step 4: Show the plot\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
